{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f2511e9-cb80-45d2-8843-da23f8ae74c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import pandas as pd\n",
    "from codalab_utils.get_names import Names\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e40ec9d-616a-4f47-9b71-a7482cf52b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = Names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81ca2d37-be47-4ac2-8873-31272cf63b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"humarin/chatgpt_paraphraser_on_T5_base\")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"humarin/chatgpt_paraphraser_on_T5_base\").to(device)\n",
    "\n",
    "def paraphrase(\n",
    "    question,\n",
    "    num_beams=5,\n",
    "    num_beam_groups=5,\n",
    "    num_return_sequences=5,\n",
    "    repetition_penalty=10.0,\n",
    "    diversity_penalty=3.0,\n",
    "    no_repeat_ngram_size=2,\n",
    "    temperature=0.7,\n",
    "    max_length=128\n",
    "):\n",
    "    input_ids = tokenizer(\n",
    "        f'paraphrase: {question}',\n",
    "        return_tensors=\"pt\", padding=\"longest\",\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "    ).input_ids.to(device)\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        input_ids, temperature=temperature, repetition_penalty=repetition_penalty,\n",
    "        num_return_sequences=num_return_sequences, no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "        num_beams=num_beams, num_beam_groups=num_beam_groups,\n",
    "        max_length=max_length, diversity_penalty=diversity_penalty\n",
    "    )\n",
    "\n",
    "    res = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ed9b71b-f99b-48a1-87c2-0f77ea7a2a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t0 : hopeedi_train.csv\n",
      "\t1 : train_polyhope_spanish_cleaned.csv\n",
      "\t2 : train_polyhope_spanish_cleaned_noemoji.csv\n",
      "\t3 : train_polyhope_english_cleaned.csv\n",
      "\t4 : train_polyhope_spanish.csv\n",
      "\t5 : train_polyhope_english.csv\n",
      "\t6 : train_polyhope_english_cleaned_noemoji.csv\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select train file :  6\n"
     ]
    }
   ],
   "source": [
    "train_file = names.train_path + names.select_file('train')\n",
    "val_file = train_file.replace('train', 'val')\n",
    "test_file = train_file.replace('train', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8661d5c5-ed61-4d7e-8bb2-3784db566404",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train =  pd.read_csv(train_file)\n",
    "df_val = pd.read_csv(val_file)\n",
    "df_test = pd.read_csv(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd218439-9428-494d-adf2-67a0038cb3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gh = df_train[df_train['multiclass'] == 'Generalized Hope']\n",
    "train_rh = df_train[df_train['multiclass'] == 'Realistic Hope']\n",
    "train_uh = df_train[df_train['multiclass'] == 'Unrealistic Hope']\n",
    "train_nh = df_train[df_train['multiclass'] == 'Not Hope']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4efd57a-20cf-47c0-be51-84c2c98d79aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_l = len(train_nh)\n",
    "d\n",
    "num_seq_gh = int(max_l/len(train_gh))\n",
    "num_seq_rh = int(max_l/len(train_rh))\n",
    "num_seq_uh = int(max_l/len(train_uh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22199b0a-47d3-4019-93e1-640ca4997d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                       | 0/1726 [00:00<?, ?it/s]/home/coep/general/bert/codalab/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      " 79%|███████████████████████████████████████████████▍            | 1363/1726 [22:59<06:07,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "train_gh_texts = train_gh['text'].tolist()\n",
    "train_gh_multi = train_gh['multiclass'].tolist()\n",
    "added_gh_texts = []\n",
    "added_gh_multi = []\n",
    "\n",
    "for t, l in tqdm(zip(train_gh_texts, train_gh_multi), total=len(train_gh_texts)):\n",
    "    if len(added_gh_multi)+len(train_gh_multi) > max_l:\n",
    "        break\n",
    "    added_gh_texts.extend(paraphrase(t, num_return_sequences=num_seq_gh))\n",
    "    added_gh_multi.extend([l]*num_seq_gh)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "219a6998-79cd-447b-9338-2971a339a558",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|██████████████████████████████████████████████████            | 590/730 [10:58<02:36,  1.12s/it]\n"
     ]
    }
   ],
   "source": [
    "train_rh_texts = train_rh['text'].tolist()\n",
    "train_rh_multi = train_rh['multiclass'].tolist()\n",
    "added_rh_texts = []\n",
    "added_rh_multi = []\n",
    "\n",
    "for t, l in tqdm(zip(train_rh_texts, train_rh_multi), total=len(train_rh_texts)):\n",
    "    if len(added_rh_multi)+len(train_rh_multi) > max_l:\n",
    "        break\n",
    "    added_rh_texts.extend(paraphrase(t, num_return_sequences=num_seq_rh))\n",
    "    added_rh_multi.extend([l]*num_seq_rh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0493611-f348-44b3-968a-f6abd7280154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                        | 0/648 [00:00<?, ?it/s]/home/coep/general/bert/codalab/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      " 94%|██████████████████████████████████████████████████████████▍   | 611/648 [09:09<00:33,  1.11it/s]\n"
     ]
    }
   ],
   "source": [
    "train_uh_texts = train_uh['text'].tolist()\n",
    "train_uh_multi = train_uh['multiclass'].tolist()\n",
    "added_uh_texts = []\n",
    "added_uh_multi = []\n",
    "\n",
    "for t, l in tqdm(zip(train_uh_texts, train_uh_multi), total=len(train_uh_texts)):\n",
    "    if len(added_uh_multi)+len(train_uh_multi) > max_l:\n",
    "        break\n",
    "    added_uh_texts.extend(paraphrase(t, num_return_sequences=num_seq_uh))\n",
    "    added_uh_multi.extend([l]*num_seq_uh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3f866c8-6e4a-4bc2-bffd-af9b40d6d9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gh = df_test[df_test['multiclass'] == 'Generalized Hope']\n",
    "test_rh = df_test[df_test['multiclass'] == 'Realistic Hope']\n",
    "test_uh = df_test[df_test['multiclass'] == 'Unrealistic Hope']\n",
    "test_nh = df_test[df_test['multiclass'] == 'Not Hope']\n",
    "\n",
    "max_l_test = len(test_nh)\n",
    "\n",
    "num_seq_gh_test = int(max_l_test/len(test_gh))\n",
    "num_seq_rh_test = int(max_l_test/len(test_rh))\n",
    "num_seq_uh_test = int(max_l_test/len(test_uh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72cf6054-73a9-482e-9863-6dfcf0bc4e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|████████████████████████████████████▋                         | 183/309 [02:58<02:02,  1.03it/s]\n"
     ]
    }
   ],
   "source": [
    "test_gh_texts = test_gh['text'].tolist()\n",
    "test_gh_multi = test_gh['multiclass'].tolist()\n",
    "added_gh_texts_test = []\n",
    "added_gh_multi_test = []\n",
    "\n",
    "for t, l in tqdm(zip(test_gh_texts, test_gh_multi), total=len(test_gh_texts)):\n",
    "    if len(added_gh_multi_test)+len(test_gh_multi) > max_l_test:\n",
    "        break\n",
    "    added_gh_texts_test.extend(paraphrase(t, num_return_sequences=num_seq_gh_test))\n",
    "    added_gh_multi_test.extend([l]*num_seq_gh_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0bbe33a-8578-45d4-b2f7-3fef820905fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████████████████████████████████████████████████████████▌| 123/124 [02:03<00:01,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "test_rh_texts = test_rh['text'].tolist()\n",
    "test_rh_multi = test_rh['multiclass'].tolist()\n",
    "added_rh_texts_test = []\n",
    "added_rh_multi_test = []\n",
    "\n",
    "for t, l in tqdm(zip(test_rh_texts, test_rh_multi), total=len(test_rh_texts)):\n",
    "    if len(added_rh_multi_test)+len(test_rh_multi) > max_l_test:\n",
    "        break\n",
    "    added_rh_texts_test.extend(paraphrase(t, num_return_sequences=num_seq_rh_test))\n",
    "    added_rh_multi_test.extend([l]*num_seq_rh_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78b985e0-0836-4261-8310-b3d3907ab6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|███████████████████████████████████████████████████████████▌       | 96/108 [01:22<00:10,  1.16it/s]\n"
     ]
    }
   ],
   "source": [
    "test_uh_texts = test_uh['text'].tolist()\n",
    "test_uh_multi = test_uh['multiclass'].tolist()\n",
    "added_uh_texts_test = []\n",
    "added_uh_multi_test = []\n",
    "\n",
    "for t, l in tqdm(zip(test_uh_texts, test_uh_multi), total=len(test_uh_texts)):\n",
    "    if len(added_uh_multi_test)+len(test_uh_multi) > max_l_test:\n",
    "        break\n",
    "    added_uh_texts_test.extend(paraphrase(t, num_return_sequences=num_seq_uh_test))\n",
    "    added_uh_multi_test.extend([l]*num_seq_uh_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c4e01a5-46b0-4c73-b73c-7cf805e20905",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_gh = df_val[df_val['multiclass'] == 'Generalized Hope']\n",
    "val_rh = df_val[df_val['multiclass'] == 'Realistic Hope']\n",
    "val_uh = df_val[df_val['multiclass'] == 'Unrealistic Hope']\n",
    "val_nh = df_val[df_val['multiclass'] == 'Not Hope']\n",
    "\n",
    "max_l_val = len(val_nh)\n",
    "\n",
    "num_seq_gh_val = int(max_l_val/len(val_gh))\n",
    "num_seq_rh_val = int(max_l_val/len(val_rh))\n",
    "num_seq_uh_val = int(max_l_val/len(val_uh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b33d03f0-cb27-477f-b6d2-14493b2a32f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|████████████████████████████████████████████▋                     | 203/300 [03:06<01:29,  1.09it/s]\n"
     ]
    }
   ],
   "source": [
    "val_gh_texts = val_gh['text'].tolist()\n",
    "val_gh_multi = val_gh['multiclass'].tolist()\n",
    "added_gh_texts_val = []\n",
    "added_gh_multi_val = []\n",
    "\n",
    "for t, l in tqdm(zip(val_gh_texts, val_gh_multi), total=len(val_gh_texts)):\n",
    "    if len(added_gh_multi_val)+len(val_gh_multi) > max_l_val:\n",
    "        break\n",
    "    added_gh_texts_val.extend(paraphrase(t, num_return_sequences=num_seq_gh_val))\n",
    "    added_gh_multi_val.extend([l]*num_seq_gh_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52f05e0c-1018-44c9-a452-bd969e9c8769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████▌ | 125/128 [02:07<00:03,  1.02s/it]\n"
     ]
    }
   ],
   "source": [
    "val_rh_texts = val_rh['text'].tolist()\n",
    "val_rh_multi = val_rh['multiclass'].tolist()\n",
    "added_rh_texts_val = []\n",
    "added_rh_multi_val = []\n",
    "\n",
    "for t, l in tqdm(zip(val_rh_texts, val_rh_multi), total=len(val_rh_texts)):\n",
    "    if len(added_rh_multi_val)+len(val_rh_multi) > max_l_val:\n",
    "        break\n",
    "    added_rh_texts_val.extend(paraphrase(t, num_return_sequences=num_seq_rh_val))\n",
    "    added_rh_multi_val.extend([l]*num_seq_rh_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9306f327-b926-40dd-be3b-bef5dccbb9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████████████████████████████████████████████████████████▍| 101/102 [01:31<00:00,  1.11it/s]\n"
     ]
    }
   ],
   "source": [
    "val_uh_texts = val_uh['text'].tolist()\n",
    "val_uh_multi = val_uh['multiclass'].tolist()\n",
    "added_uh_texts_val = []\n",
    "added_uh_multi_val = []\n",
    "\n",
    "for t, l in tqdm(zip(val_uh_texts, val_uh_multi), total=len(val_uh_texts)):\n",
    "    if len(added_uh_multi_val)+len(val_uh_multi) > max_l_val:\n",
    "        break\n",
    "    added_uh_texts_val.extend(paraphrase(t, num_return_sequences=num_seq_uh_val))\n",
    "    added_uh_multi_val.extend([l]*num_seq_uh_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff69e24-22be-4f82-837b-63814b8a8172",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_texts = df_train['text'].tolist() + train_gh_texts + train_rh_texts + train_uh_texts\n",
    "new_train_labels = df_train['multiclass'].tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
