{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1265427-c25c-4c72-abe8-ed0ec4d8b7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a6d4399-ea7f-4b3d-9f7b-579c895e0cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "\tdef __init__(self, bert_model_name, num_classes):\n",
    "\t\tsuper(BERTClassifier, self).__init__()\n",
    "\t\tself.bert = BertModel.from_pretrained(bert_model_name)\n",
    "\t\tself.dropout = nn.Dropout(0.1)\n",
    "\t\tself.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "\t\t\n",
    "\tdef forward(self, input_ids, attention_mask):\n",
    "\t\toutputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\t\tpooled_output = outputs.pooler_output\n",
    "\t\tx = self.dropout(pooled_output)\n",
    "\t\tlogits = self.fc(x)\n",
    "\t\treturn logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da74e6a-93d1-47ed-8053-5e7f321072be",
   "metadata": {},
   "outputs": [],
   "source": [
    "polyhope_multi_labels = {'Not Hope':0, 'Generalized Hope':1, 'Realistic Hope':2, 'Unrealistic Hope':3}\n",
    "polyhope_inv_multi_labels = {v: k for k, v in polyhope_multi_labels.items()}\n",
    "polyhope_binary_labels = {'Hope':1, 'Not Hope':0}\n",
    "polyhope_inv_binary_labels = {v: k for k, v in polyhope_binary_labels.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1154c829-adfb-485d-8b2d-51eb7cea2025",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#'dccuchile/bert-base-spanish-wwm-cased'\n",
    "model_name = 'bert-base-uncased' \n",
    "num_classes = 4\n",
    "device = torch.device('cpu')\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = BERTClassifier(model_name, num_classes)\n",
    "model.load_state_dict(torch.load('../models/poly_multi_english_uncased.pth', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "823c47ba-71c5-474c-861a-eed3723ef195",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_sentiment(text, label_map, model, tokenizer, device, max_length=128):\n",
    "    model.eval()\n",
    "    encoding = tokenizer(text, return_tensors='pt', max_length=max_length, padding='max_length', truncation=True)\n",
    "    input_ids = encoding['input_ids']\n",
    "    attention_mask = encoding['attention_mask']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        return label_map[preds.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84e69b0a-9678-46b0-8cf7-286d9aeffdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = 'this is a good example'\n",
    "# predict_sentiment(test, model, tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c71dd80a-93d7-4889-834c-d5b1940b1099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(text, model, tokenizer, device, max_length=128):\n",
    "    model.eval()\n",
    "    encoding = tokenizer(text, return_tensors='pt', max_length=max_length, padding='max_length', truncation=True)\n",
    "    input_ids = encoding['input_ids']\n",
    "    attention_mask = encoding['attention_mask']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return outputs.pooler_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebbb2f8f-e34a-46e7-b0ed-fd9e654ebad9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 200/200 [00:42<00:00,  4.67it/s]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/val_polyhope_english.csv')\n",
    "actual_predictions = df['category'].tolist()\n",
    "texts = df['text'].tolist()\n",
    "\n",
    "for i, text in enumerate(tqdm(texts)):\n",
    "    embeddings.append(get_embeddings(text, model, tokenizer, device)[0].numpy())\n",
    "    pred.append(predict_sentiment(text, polyhope_inv_multi_labels, model, tokenizer, device))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
